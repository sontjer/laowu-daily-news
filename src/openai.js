import { LLM } from '../config/sources.js'

export async function summarizeNews(newsItems) {
  if (!LLM.apiKey) {
    console.log('No LLM API key, using raw news')
    return newsItems.map(n => `ã€${n.source}ã€‘${n.title}`).join('\n\n')
  }
  
  const prompt = `è¯·å°†ä»¥ä¸‹æ–°é—»æ•´ç†æˆ"è€äº”ç®€æŠ¥"é£æ ¼çš„Markdownæ–‡æœ¬ã€‚

**æ ¸å¿ƒè¦æ±‚ï¼šæ‰€æœ‰æ–°é—»å¿…é¡»å’Œä¸­å›½ç›¸å…³ï¼éä¸­å›½ç›¸å…³çš„æ–°é—»å¿½ç•¥æˆ–è·³è¿‡ã€‚**

æ ¼å¼è¦æ±‚ï¼š
1. å¼€å¤´ï¼šä¸€å¥è¯å¯¼è¯­ï¼ˆä¸è¶…è¿‡20å­—ï¼‰
2. æŒ‰ç±»åˆ«åˆ†ç»„ï¼Œæ¯ç±»ç”¨emoji+ä¸­æ–‡æ ‡é¢˜ï¼ˆå¦‚## ğŸ“° å›½é™…ã€## ğŸ’° ç»æµï¼‰
3. æ¯æ¡æ–°é—»æ ¼å¼ï¼š
   **æ ‡é¢˜**ï¼ˆ15-30å­—ï¼Œç®€æ´æœ‰åŠ›ï¼‰
   - æè¿°ï¼š200-300å­—ï¼ŒåŒ…å«å…³é”®èƒŒæ™¯ã€æ•°æ®ã€å½±å“

æ–°é—»ï¼š
${newsItems.map((n, i) => `${i + 1}. [${n.source}] ${n.title}`).join('\n')}

è¦æ±‚ï¼š
- ç”¨Markdownæ ¼å¼è¾“å‡º
- ç”¨ä¸­æ–‡è¾“å‡º
- **åªé€‰æ‹©å’Œä¸­å›½ç›¸å…³çš„æ–°é—»**
- éä¸­å›½çš„æ–°é—»ç›´æ¥è·³è¿‡ï¼Œä¸è¦æ”¾å…¥ç®€æŠ¥
- æ ‡é¢˜è¦æŠ“äººçœ¼çƒ
- æè¿°è¦æœ‰ä¿¡æ¯å¢é‡ï¼ˆèƒŒæ™¯ã€æ•°æ®ã€å½±å“ï¼‰
- ç§‘æŠ€/ç»æµç±»è¦åŒ…å«å…·ä½“æ•°å­—
- ç›¸åŒç±»åˆ«æ”¾ä¸€èµ·
- é‡è¦æ”¾å‰é¢`

  let response
  
  if (LLM.provider === 'deepseek' || LLM.provider === 'siliconflow') {
    response = await fetch(`${LLM.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${LLM.apiKey}`
      },
      body: JSON.stringify({
        model: LLM.model,
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 4000
      })
    })
  }
  
  const data = await response.json()
  return data.choices?.[0]?.message?.content || 'æ‘˜è¦ç”Ÿæˆå¤±è´¥'
}

export async function fetchArticleContent(url) {
  const fetch = (await import('node-fetch')).default
  
  try {
    const response = await fetch(`https://r.jina.ai/${url}`)
    const text = await response.text()
    return text.slice(0, 3000)
  } catch {
    return ''
  }
}
